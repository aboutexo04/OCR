{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR Text Detection - High Precision Focus\n",
    "\n",
    "**목표**: Precision을 86% → 93%+ 로 개선하면서 Recall 유지\n",
    "\n",
    "## 기존 문제점 분석\n",
    "- threshold 0.5 → false positive 과다\n",
    "- morphological cleanup 없음 → 노이즈 검출\n",
    "- min_area=30 너무 작음\n",
    "- 경계면 bleed → 비텍스트 영역 검출\n",
    "\n",
    "## 개선 전략\n",
    "1. **Focal + Dice + Boundary Loss**: 경계면 false positive에 강한 패널티\n",
    "2. **Morphological post-processing**: 노이즈 제거 + 마스크 정제\n",
    "3. **Adaptive threshold**: 고신뢰 영역만 검출\n",
    "4. **Aspect ratio / area filtering**: 텍스트답지 않은 영역 제거\n",
    "5. **Multi-scale TTA**: 여러 스케일 예측 교집합으로 precision 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 다운로드 (Colab 환경)\n",
    "!wget -O data.tar.gz \"https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000377/data/data.tar.gz\"\n",
    "!tar -xzf data.tar.gz\n",
    "!pip install -q segmentation-models-pytorch albumentations opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.amp import autocast, GradScaler\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport segmentation_models_pytorch as smp\nfrom tqdm import tqdm\nimport gc\n\n# ========================================\n# GPU 최적화\n# ========================================\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\ntorch.backends.cuda.matmul.allow_tf32 = True\ntorch.backends.cudnn.allow_tf32 = True\ntorch.backends.cudnn.benchmark = True\n\n# ========================================\n# 경로 설정\n# ========================================\nBASE_PATH = './data/datasets'\nTRAIN_IMG_DIR = os.path.join(BASE_PATH, 'images/train')\nVAL_IMG_DIR = os.path.join(BASE_PATH, 'images/val')\nTEST_IMG_DIR = os.path.join(BASE_PATH, 'images/test')\nTRAIN_JSON = os.path.join(BASE_PATH, 'jsons/train.json')\nVAL_JSON = os.path.join(BASE_PATH, 'jsons/val.json')\nTEST_JSON = os.path.join(BASE_PATH, 'jsons/test.json')\nSAMPLE_SUB = os.path.join(BASE_PATH, 'sample_submission.csv')\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Device: {DEVICE}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n\n# ========================================\n# 하이퍼파라미터 (Precision 최적화)\n# ========================================\nRESIZE_TARGET = 1024\nBATCH_SIZE = 4\nACCUMULATION_STEPS = 8   # 실효 배치 32\nEPOCHS = 40\nLEARNING_RATE = 5e-4\nWARMUP_EPOCHS = 3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 2. 데이터셋 클래스\n",
    "# ========================================\n",
    "class ReceiptDataset(Dataset):\n",
    "    def __init__(self, img_dir, json_path, transform=None, is_test=False):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            self.data = json.load(f)['images']\n",
    "        self.image_names = list(self.data.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_names[idx]\n",
    "        image = cv2.imread(os.path.join(self.img_dir, img_name))\n",
    "        if image is None:\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        if not self.is_test:\n",
    "            # 텍스트 영역 마스크 생성\n",
    "            mask = np.zeros((h, w), dtype=np.float32)\n",
    "            words = self.data[img_name].get('words', {})\n",
    "            for word_id in words:\n",
    "                pts = np.array(words[word_id]['points'], dtype=np.int32)\n",
    "                cv2.fillPoly(mask, [pts], 1)\n",
    "\n",
    "            # 경계선(boundary) 마스크 생성 - precision 개선 핵심\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            dilated = cv2.dilate(mask, kernel, iterations=2)\n",
    "            eroded = cv2.erode(mask, kernel, iterations=2)\n",
    "            boundary = dilated - eroded\n",
    "\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image, masks=[mask, boundary])\n",
    "                img_t = augmented['image']\n",
    "                mask_t = augmented['masks'][0]\n",
    "                boundary_t = augmented['masks'][1]\n",
    "                return img_t, mask_t, boundary_t\n",
    "        else:\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image)\n",
    "                return augmented['image'], img_name, (h, w)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3. 증강 파이프라인 (과도한 증강 제거 - Precision 보호)\n",
    "# ========================================\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(RESIZE_TARGET, RESIZE_TARGET),\n",
    "    # 기하학적 증강 (적당히)\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=5, p=0.4,\n",
    "                       border_mode=cv2.BORDER_CONSTANT, value=0),\n",
    "    # 색상/밝기 증강 (영수증 다양성 대응)\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
    "        A.CLAHE(clip_limit=2.0, p=1.0),\n",
    "    ], p=0.4),\n",
    "    A.OneOf([\n",
    "        A.GaussianBlur(blur_limit=3, p=1.0),\n",
    "        A.MedianBlur(blur_limit=3, p=1.0),\n",
    "    ], p=0.2),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(RESIZE_TARGET, RESIZE_TARGET),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ========================================\n# 4. Precision 중심 손실 함수\n# ========================================\n\nclass FocalLoss(nn.Module):\n    \"\"\"Focal Loss: false positive에 강한 패널티\"\"\"\n    def __init__(self, alpha=0.75, gamma=2.0):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, pred, target):\n        pred_sig = torch.sigmoid(pred)\n        # alpha를 높여서 false positive(배경을 텍스트로 예측)에 더 큰 패널티\n        alpha_t = self.alpha * target + (1 - self.alpha) * (1 - target)\n        ce = F.binary_cross_entropy_with_logits(pred, target, reduction='none')\n        p_t = pred_sig * target + (1 - pred_sig) * (1 - target)\n        focal_weight = alpha_t * (1 - p_t) ** self.gamma\n        return (focal_weight * ce).mean()\n\n\nclass BoundaryLoss(nn.Module):\n    \"\"\"경계면에 집중하는 Loss - 마스크 경계를 선명하게\"\"\"\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, pred, boundary_mask):\n        bce = F.binary_cross_entropy_with_logits(pred, boundary_mask, reduction='none')\n        weight = 1.0 + 4.0 * boundary_mask\n        return (weight * bce).mean()\n\n\nclass PrecisionFocusedLoss(nn.Module):\n    \"\"\"\n    Precision 개선 복합 손실 함수\n    = Focal Loss (FP 억제) + Dice Loss (영역 정합) + Boundary Loss (경계 선명도)\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        self.focal = FocalLoss(alpha=0.75, gamma=2.0)\n        self.dice = smp.losses.DiceLoss(mode='binary')\n        self.boundary = BoundaryLoss()\n\n    def forward(self, pred, mask, boundary_mask):\n        mask = mask.unsqueeze(1) if mask.dim() == 3 else mask\n        boundary_mask = boundary_mask.unsqueeze(1) if boundary_mask.dim() == 3 else boundary_mask\n\n        l_focal = self.focal(pred, mask)\n        l_dice = self.dice(pred, mask)\n        l_boundary = self.boundary(pred, boundary_mask)\n\n        # Focal 비중을 높여 false positive 억제\n        return 0.4 * l_focal + 0.4 * l_dice + 0.2 * l_boundary"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 5. 후처리 파이프라인 (Precision 핵심)\n",
    "# ========================================\n",
    "\n",
    "def refine_mask(mask_prob, threshold=0.65):\n",
    "    \"\"\"\n",
    "    마스크 정제: threshold → morphological cleanup → 노이즈 제거\n",
    "    threshold를 0.5 → 0.65로 올려 고신뢰 영역만 남김\n",
    "    \"\"\"\n",
    "    binary = (mask_prob > threshold).astype(np.uint8)\n",
    "\n",
    "    # Step 1: morphological opening (침식→팽창) - 작은 노이즈 제거\n",
    "    kernel_small = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_small, iterations=1)\n",
    "\n",
    "    # Step 2: morphological closing (팽창→침식) - 작은 구멍 채움\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 3))\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel_close, iterations=1)\n",
    "\n",
    "    return binary\n",
    "\n",
    "\n",
    "def mask_to_polygons_precise(mask, orig_h, orig_w, min_area=80):\n",
    "    \"\"\"\n",
    "    Precision 최적화 폴리곤 추출\n",
    "    - min_area 상향 (30→80): 작은 노이즈 제거\n",
    "    - aspect ratio 필터: 텍스트답지 않은 정사각/세로 영역 제거\n",
    "    - minAreaRect 기반 4점 폴리곤: 깔끔한 사각형 검출\n",
    "    \"\"\"\n",
    "    polygons = []\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area < min_area:\n",
    "            continue\n",
    "\n",
    "        # 최소 외접 회전 사각형\n",
    "        rect = cv2.minAreaRect(cnt)\n",
    "        box_w, box_h = rect[1]\n",
    "        if box_w == 0 or box_h == 0:\n",
    "            continue\n",
    "\n",
    "        # 너무 작은 영역 필터링 (원본 해상도 기준)\n",
    "        if min(box_w, box_h) < 4:\n",
    "            continue\n",
    "\n",
    "        # 폴리곤 근사: epsilon을 적당히 설정\n",
    "        epsilon = 0.01 * cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, epsilon, True)\n",
    "\n",
    "        if len(approx) >= 4:\n",
    "            points = approx.reshape(-1, 2).tolist()\n",
    "            polygons.append(points)\n",
    "        elif len(cnt) >= 4:\n",
    "            # 컨투어가 단순해도 minAreaRect로 4점 생성\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int32(box)\n",
    "            polygons.append(box.tolist())\n",
    "\n",
    "    return polygons\n",
    "\n",
    "\n",
    "def polygons_to_string(polygons):\n",
    "    if not polygons:\n",
    "        return \"\"\n",
    "    parts = []\n",
    "    for poly in polygons:\n",
    "        coords = \" \".join([f\"{int(p[0])} {int(p[1])}\" for p in poly])\n",
    "        parts.append(coords)\n",
    "    return \"|\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 6. 학습 함수\n",
    "# ========================================\n",
    "\n",
    "def train():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # 데이터 로더\n",
    "    train_ds = ReceiptDataset(TRAIN_IMG_DIR, TRAIN_JSON, transform=train_transform)\n",
    "    val_ds = ReceiptDataset(VAL_IMG_DIR, VAL_JSON, transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "        num_workers=4, pin_memory=True, drop_last=True, persistent_workers=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "        num_workers=4, pin_memory=True, persistent_workers=True\n",
    "    )\n",
    "\n",
    "    # 모델: EfficientNet-b4 (b3보다 강력, 메모리 허용범위)\n",
    "    model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"efficientnet-b4\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=1\n",
    "    ).to(DEVICE)\n",
    "    model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "    # Optimizer: AdamW + OneCycleLR (warmup 포함)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-2)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=LEARNING_RATE,\n",
    "        epochs=EPOCHS,\n",
    "        steps_per_epoch=len(train_loader) // ACCUMULATION_STEPS,\n",
    "        pct_start=WARMUP_EPOCHS / EPOCHS,\n",
    "        anneal_strategy='cos'\n",
    "    )\n",
    "\n",
    "    criterion = PrecisionFocusedLoss()\n",
    "    scaler = GradScaler('cuda')\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 0\n",
    "    max_patience = 8\n",
    "\n",
    "    print(f\"=== Training Start ===\")\n",
    "    print(f\"    Model: UNet++ / EfficientNet-b4\")\n",
    "    print(f\"    Resolution: {RESIZE_TARGET}x{RESIZE_TARGET}\")\n",
    "    print(f\"    Effective Batch: {BATCH_SIZE * ACCUMULATION_STEPS}\")\n",
    "    print(f\"    Epochs: {EPOCHS}, LR: {LEARNING_RATE}\")\n",
    "    print(f\"    Loss: Focal(0.4) + Dice(0.4) + Boundary(0.2)\")\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch}/{EPOCHS}\")\n",
    "        for step, (images, masks, boundaries) in pbar:\n",
    "            images = images.to(DEVICE, non_blocking=True, memory_format=torch.channels_last)\n",
    "            masks = masks.to(DEVICE, non_blocking=True)\n",
    "            boundaries = boundaries.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            with autocast('cuda', dtype=torch.bfloat16):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks, boundaries) / ACCUMULATION_STEPS\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (step + 1) % ACCUMULATION_STEPS == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                scheduler.step()\n",
    "\n",
    "            train_loss += loss.item() * ACCUMULATION_STEPS\n",
    "            pbar.set_postfix({'loss': f'{loss.item() * ACCUMULATION_STEPS:.4f}'})\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, masks, boundaries in val_loader:\n",
    "                images = images.to(DEVICE, non_blocking=True, memory_format=torch.channels_last)\n",
    "                masks = masks.to(DEVICE, non_blocking=True)\n",
    "                boundaries = boundaries.to(DEVICE, non_blocking=True)\n",
    "                with autocast('cuda', dtype=torch.bfloat16):\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, masks, boundaries)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_train = train_loss / len(train_loader)\n",
    "        avg_val = val_loss / len(val_loader)\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        print(f\"Epoch {epoch}: Train={avg_train:.4f}, Val={avg_val:.4f}, LR={lr:.6f}\")\n",
    "\n",
    "        if avg_val < best_val_loss:\n",
    "            best_val_loss = avg_val\n",
    "            torch.save(model.state_dict(), 'best_precision_model.pth')\n",
    "            print(f\"  -> Best model saved! (val_loss={avg_val:.4f})\")\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= max_patience:\n",
    "                print(f\"  -> Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "        mem = torch.cuda.max_memory_allocated() / 1e9\n",
    "        print(f\"  -> Peak Memory: {mem:.1f} GB\")\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    print(f\"Training complete. Best val_loss={best_val_loss:.4f}\")\n",
    "    return model\n",
    "\n",
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 7. Multi-Scale TTA 추론 (Precision 극대화)\n",
    "# ========================================\n",
    "\n",
    "def inference_multiscale_tta():\n",
    "    print(\"=== High-Precision Inference (Multi-Scale TTA) ===\")\n",
    "\n",
    "    # 모델 로드\n",
    "    model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"efficientnet-b4\",\n",
    "        encoder_weights=None,\n",
    "        in_channels=3,\n",
    "        classes=1\n",
    "    ).to(DEVICE)\n",
    "    model.load_state_dict(torch.load('best_precision_model.pth', map_location=DEVICE))\n",
    "    model = model.to(memory_format=torch.channels_last)\n",
    "    model.eval()\n",
    "\n",
    "    # 테스트 데이터 로드 (원본 이미지 직접 읽기)\n",
    "    with open(TEST_JSON, 'r', encoding='utf-8') as f:\n",
    "        test_data = json.load(f)['images']\n",
    "    test_names = list(test_data.keys())\n",
    "\n",
    "    sample_df = pd.read_csv(SAMPLE_SUB)\n",
    "    predictions = {}\n",
    "\n",
    "    # Multi-Scale 설정: 여러 해상도에서 예측 후 평균\n",
    "    # → 여러 스케일에서 모두 높은 확률인 영역만 남음 → Precision 향상\n",
    "    scales = [896, 1024, 1152]\n",
    "\n",
    "    normalize = A.Normalize()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_name in tqdm(test_names, desc=\"Inference\"):\n",
    "            image = cv2.imread(os.path.join(TEST_IMG_DIR, img_name))\n",
    "            if image is None:\n",
    "                predictions[img_name] = \"\"\n",
    "                continue\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            orig_h, orig_w = image.shape[:2]\n",
    "\n",
    "            accumulated_mask = np.zeros((orig_h, orig_w), dtype=np.float32)\n",
    "            n_preds = 0\n",
    "\n",
    "            for scale in scales:\n",
    "                # 리사이즈 + 정규화\n",
    "                resized = cv2.resize(image, (scale, scale))\n",
    "                normed = normalize(image=resized)['image']\n",
    "                tensor = torch.from_numpy(normed.transpose(2, 0, 1)).float().unsqueeze(0)\n",
    "                tensor = tensor.to(DEVICE, memory_format=torch.channels_last)\n",
    "\n",
    "                with autocast('cuda', dtype=torch.bfloat16):\n",
    "                    # 원본 예측\n",
    "                    p1 = torch.sigmoid(model(tensor))\n",
    "                    # 좌우반전 TTA\n",
    "                    p2 = torch.sigmoid(model(torch.flip(tensor, dims=[3])))\n",
    "                    p2 = torch.flip(p2, dims=[3])\n",
    "\n",
    "                avg = ((p1 + p2) / 2).float().cpu().numpy()[0, 0]\n",
    "                # 원본 해상도로 복원\n",
    "                avg_orig = cv2.resize(avg, (orig_w, orig_h), interpolation=cv2.INTER_LINEAR)\n",
    "                accumulated_mask += avg_orig\n",
    "                n_preds += 1\n",
    "\n",
    "            # 스케일 평균\n",
    "            final_mask = accumulated_mask / n_preds\n",
    "\n",
    "            # 후처리 (Precision 핵심)\n",
    "            refined = refine_mask(final_mask, threshold=0.65)\n",
    "            polygons = mask_to_polygons_precise(refined, orig_h, orig_w, min_area=80)\n",
    "            predictions[img_name] = polygons_to_string(polygons)\n",
    "\n",
    "    # 제출 파일 생성\n",
    "    sample_df['polygons'] = sample_df['filename'].map(predictions).fillna(\"\")\n",
    "    sample_df.to_csv('submission_high_precision.csv', index=False)\n",
    "\n",
    "    # 통계\n",
    "    poly_counts = sample_df['polygons'].apply(lambda x: len(x.split('|')) if x else 0)\n",
    "    print(f\"\\n=== Results ===\")\n",
    "    print(f\"    Total images: {len(sample_df)}\")\n",
    "    print(f\"    Avg polygons/image: {poly_counts.mean():.1f}\")\n",
    "    print(f\"    Min polygons: {poly_counts.min()}, Max: {poly_counts.max()}\")\n",
    "    print(f\"    Saved: submission_high_precision.csv\")\n",
    "\n",
    "inference_multiscale_tta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 8. Threshold 탐색 (최적 Precision-Recall 밸런스 찾기)\n",
    "# ========================================\n",
    "\n",
    "def search_optimal_threshold():\n",
    "    \"\"\"\n",
    "    Validation 셋에서 threshold별 검출 수를 비교하여\n",
    "    최적의 threshold를 탐색합니다.\n",
    "    \"\"\"\n",
    "    print(\"=== Threshold Search on Validation ===\")\n",
    "\n",
    "    model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"efficientnet-b4\",\n",
    "        encoder_weights=None,\n",
    "        in_channels=3,\n",
    "        classes=1\n",
    "    ).to(DEVICE)\n",
    "    model.load_state_dict(torch.load('best_precision_model.pth', map_location=DEVICE))\n",
    "    model = model.to(memory_format=torch.channels_last)\n",
    "    model.eval()\n",
    "\n",
    "    # Validation GT 로드\n",
    "    with open(VAL_JSON, 'r', encoding='utf-8') as f:\n",
    "        val_data = json.load(f)['images']\n",
    "\n",
    "    normalize = A.Normalize()\n",
    "    thresholds = [0.50, 0.55, 0.60, 0.65, 0.70, 0.75]\n",
    "\n",
    "    # 샘플 50개로 빠르게 탐색\n",
    "    sample_names = list(val_data.keys())[:50]\n",
    "\n",
    "    for thresh in thresholds:\n",
    "        total_gt = 0\n",
    "        total_pred = 0\n",
    "\n",
    "        for img_name in sample_names:\n",
    "            gt_words = val_data[img_name].get('words', {})\n",
    "            total_gt += len(gt_words)\n",
    "\n",
    "            image = cv2.imread(os.path.join(VAL_IMG_DIR, img_name))\n",
    "            if image is None:\n",
    "                continue\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            orig_h, orig_w = image.shape[:2]\n",
    "\n",
    "            resized = cv2.resize(image, (1024, 1024))\n",
    "            normed = normalize(image=resized)['image']\n",
    "            tensor = torch.from_numpy(normed.transpose(2, 0, 1)).float().unsqueeze(0)\n",
    "            tensor = tensor.to(DEVICE, memory_format=torch.channels_last)\n",
    "\n",
    "            with torch.no_grad(), autocast('cuda', dtype=torch.bfloat16):\n",
    "                pred = torch.sigmoid(model(tensor)).float().cpu().numpy()[0, 0]\n",
    "\n",
    "            pred_resized = cv2.resize(pred, (orig_w, orig_h))\n",
    "            refined = refine_mask(pred_resized, threshold=thresh)\n",
    "            polygons = mask_to_polygons_precise(refined, orig_h, orig_w, min_area=80)\n",
    "            total_pred += len(polygons)\n",
    "\n",
    "        ratio = total_pred / total_gt if total_gt > 0 else 0\n",
    "        print(f\"  Threshold={thresh:.2f}: GT={total_gt}, Pred={total_pred}, Pred/GT={ratio:.3f}\")\n",
    "        # Pred/GT가 1.0에 가까울수록 좋음 (>1.0은 false positive 많음)\n",
    "\n",
    "search_optimal_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 9. (선택) 최적 threshold로 재추론\n",
    "# ========================================\n",
    "# 위 탐색 결과에서 Pred/GT가 0.95~1.05 사이인 threshold를 선택하세요.\n",
    "# 예: threshold=0.65가 최적이면 그대로 유지, 0.70이 더 좋으면 아래 수정\n",
    "#\n",
    "# OPTIMAL_THRESHOLD = 0.65  # 탐색 결과에 따라 조정\n",
    "# refine_mask() 함수의 threshold 파라미터를 변경 후\n",
    "# inference_multiscale_tta() 를 다시 실행하면 됩니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}