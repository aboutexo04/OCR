{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup\n",
    "!wget -O data.tar.gz \"https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000377/data/data.tar.gz\"\n",
    "!tar -xzf data.tar.gz\n",
    "!pip install -q segmentation-models-pytorch albumentations opencv-python-headless pyclipper shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports + Config\n",
    "import os, json, cv2, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import pyclipper\n",
    "from shapely.geometry import Polygon as ShapelyPolygon\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "BASE = './data/datasets'\n",
    "TRAIN_IMG = os.path.join(BASE, 'images/train')\n",
    "VAL_IMG = os.path.join(BASE, 'images/val')\n",
    "TEST_IMG = os.path.join(BASE, 'images/test')\n",
    "TRAIN_JSON = os.path.join(BASE, 'jsons/train.json')\n",
    "VAL_JSON = os.path.join(BASE, 'jsons/val.json')\n",
    "TEST_JSON = os.path.join(BASE, 'jsons/test.json')\n",
    "SAMPLE_SUB = os.path.join(BASE, 'sample_submission.csv')\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "SZ = 1024\n",
    "BS = 4\n",
    "ACCUM = 8\n",
    "EPOCHS = 25\n",
    "LR = 1e-3\n",
    "SHRINK = 0.4\n",
    "K_AMP = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: DBNet Model (ResNet50 + FPN + Differentiable Binarization)\n",
    "class DBNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        bb = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.stem = nn.Sequential(bb.conv1, bb.bn1, bb.relu, bb.maxpool)\n",
    "        self.layer1 = bb.layer1   # 256,  /4\n",
    "        self.layer2 = bb.layer2   # 512,  /8\n",
    "        self.layer3 = bb.layer3   # 1024, /16\n",
    "        self.layer4 = bb.layer4   # 2048, /32\n",
    "\n",
    "        C = 256\n",
    "        self.lat4 = nn.Conv2d(2048, C, 1)\n",
    "        self.lat3 = nn.Conv2d(1024, C, 1)\n",
    "        self.lat2 = nn.Conv2d(512, C, 1)\n",
    "        self.lat1 = nn.Conv2d(256, C, 1)\n",
    "\n",
    "        self.sm4 = nn.Conv2d(C, 64, 3, padding=1)\n",
    "        self.sm3 = nn.Conv2d(C, 64, 3, padding=1)\n",
    "        self.sm2 = nn.Conv2d(C, 64, 3, padding=1)\n",
    "        self.sm1 = nn.Conv2d(C, 64, 3, padding=1)\n",
    "\n",
    "        self.prob_head = nn.Sequential(\n",
    "            nn.Conv2d(C, 64, 3, padding=1, bias=False), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, 1))\n",
    "        self.thresh_head = nn.Sequential(\n",
    "            nn.Conv2d(C, 64, 3, padding=1, bias=False), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        H, W = x.shape[2:]\n",
    "        x = self.stem(x)\n",
    "        c1 = self.layer1(x)\n",
    "        c2 = self.layer2(c1)\n",
    "        c3 = self.layer3(c2)\n",
    "        c4 = self.layer4(c3)\n",
    "\n",
    "        p4 = self.lat4(c4)\n",
    "        p3 = self.lat3(c3) + F.interpolate(p4, size=c3.shape[2:], mode='nearest')\n",
    "        p2 = self.lat2(c2) + F.interpolate(p3, size=c2.shape[2:], mode='nearest')\n",
    "        p1 = self.lat1(c1) + F.interpolate(p2, size=c1.shape[2:], mode='nearest')\n",
    "\n",
    "        s = c1.shape[2:]\n",
    "        fused = torch.cat([\n",
    "            self.sm1(p1),\n",
    "            self.sm2(F.interpolate(p2, size=s, mode='nearest')),\n",
    "            self.sm3(F.interpolate(p3, size=s, mode='nearest')),\n",
    "            self.sm4(F.interpolate(p4, size=s, mode='nearest')),\n",
    "        ], dim=1)\n",
    "\n",
    "        prob_logits = F.interpolate(self.prob_head(fused), (H, W), mode='bilinear', align_corners=False)\n",
    "        thresh_logits = F.interpolate(self.thresh_head(fused), (H, W), mode='bilinear', align_corners=False)\n",
    "\n",
    "        prob = torch.sigmoid(prob_logits)\n",
    "        thresh = torch.sigmoid(thresh_logits)\n",
    "        binary = torch.sigmoid(K_AMP * (prob - thresh))\n",
    "\n",
    "        return prob_logits, prob, thresh, binary\n",
    "\n",
    "model = DBNet().to(DEVICE)\n",
    "print(f\"Params: {sum(p.numel() for p in model.parameters())/1e6:.1f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: GT Generation + Dataset\n",
    "\n",
    "def shrink_poly(polygon, ratio=0.4):\n",
    "    try:\n",
    "        poly = ShapelyPolygon(polygon)\n",
    "        if not poly.is_valid: poly = poly.buffer(0)\n",
    "        if poly.area < 1: return None\n",
    "        D = poly.area * (1 - ratio**2) / (poly.length + 1e-6)\n",
    "        pco = pyclipper.PyclipperOffset()\n",
    "        pco.AddPath([(int(p[0]), int(p[1])) for p in polygon],\n",
    "                    pyclipper.JT_ROUND, pyclipper.ET_CLOSEDPOLYGON)\n",
    "        shrunk = pco.Execute(int(-D))\n",
    "        if not shrunk: return None\n",
    "        return np.array(shrunk[0], dtype=np.int32)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def expand_poly(polygon, ratio=1.5):\n",
    "    try:\n",
    "        poly = ShapelyPolygon(polygon)\n",
    "        if not poly.is_valid: poly = poly.buffer(0)\n",
    "        if poly.area < 1: return polygon\n",
    "        D = poly.area * (1 - 1/ratio**2) / (poly.length + 1e-6)\n",
    "        pco = pyclipper.PyclipperOffset()\n",
    "        pco.AddPath([(int(p[0]), int(p[1])) for p in polygon],\n",
    "                    pyclipper.JT_ROUND, pyclipper.ET_CLOSEDPOLYGON)\n",
    "        expanded = pco.Execute(int(D))\n",
    "        if not expanded: return polygon\n",
    "        return np.array(expanded[0], dtype=np.int32)\n",
    "    except:\n",
    "        return polygon\n",
    "\n",
    "def make_gt(h, w, polygons):\n",
    "    \"\"\"Fast GT: prob(shrunk), binary(original), thresh(distance), thresh_mask\"\"\"\n",
    "    gt_binary = np.zeros((h, w), dtype=np.float32)\n",
    "    gt_prob = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "    for poly in polygons:\n",
    "        pts = np.array(poly, dtype=np.int32)\n",
    "        if len(pts) < 3: continue\n",
    "        cv2.fillPoly(gt_binary, [pts], 1.0)\n",
    "        shrunk = shrink_poly(pts, SHRINK)\n",
    "        if shrunk is not None and len(shrunk) >= 3:\n",
    "            cv2.fillPoly(gt_prob, [shrunk], 1.0)\n",
    "\n",
    "    bu = gt_binary.astype(np.uint8)\n",
    "    d_out = cv2.distanceTransform(1 - bu, cv2.DIST_L2, 5)\n",
    "    d_in  = cv2.distanceTransform(bu, cv2.DIST_L2, 5)\n",
    "    D = 8.0\n",
    "    combined = np.where(bu > 0, d_in, d_out)\n",
    "    gt_thresh = (1.0 - np.clip(combined / D, 0, 1)).astype(np.float32)\n",
    "    gt_thresh_mask = (combined < D).astype(np.float32)\n",
    "\n",
    "    return gt_prob, gt_binary, gt_thresh, gt_thresh_mask\n",
    "\n",
    "class OCRDataset(Dataset):\n",
    "    def __init__(self, img_dir, json_path, transform=None, is_test=False):\n",
    "        self.img_dir, self.transform, self.is_test = img_dir, transform, is_test\n",
    "        with open(json_path, 'r') as f:\n",
    "            self.data = json.load(f)['images']\n",
    "        self.names = list(self.data.keys())\n",
    "\n",
    "    def __len__(self): return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.names[idx]\n",
    "        img = cv2.imread(os.path.join(self.img_dir, name))\n",
    "        if img is None: return self.__getitem__((idx+1) % len(self))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        if self.is_test:\n",
    "            if self.transform:\n",
    "                img = self.transform(image=img)['image']\n",
    "            return img, name, (h, w)\n",
    "\n",
    "        words = self.data[name].get('words', {})\n",
    "        polys = [words[k]['points'] for k in words if len(words[k].get('points', [])) >= 3]\n",
    "        gt_p, gt_b, gt_t, gt_tm = make_gt(h, w, polys)\n",
    "\n",
    "        if self.transform:\n",
    "            aug = self.transform(image=img, masks=[gt_p, gt_b, gt_t, gt_tm])\n",
    "            img = aug['image']\n",
    "            gt_p, gt_b, gt_t, gt_tm = aug['masks']\n",
    "\n",
    "        return img, gt_p, gt_b, gt_t, gt_tm\n",
    "\n",
    "train_tf = A.Compose([\n",
    "    A.Resize(SZ, SZ),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10,\n",
    "                       border_mode=cv2.BORDER_CONSTANT, p=0.4),\n",
    "    A.RandomBrightnessContrast(0.2, 0.2, p=0.3),\n",
    "    A.Normalize(), ToTensorV2()\n",
    "])\n",
    "val_tf = A.Compose([A.Resize(SZ, SZ), A.Normalize(), ToTensorV2()])\n",
    "\n",
    "print(\"Dataset ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Loss + Training\n",
    "\n",
    "def dice_loss(pred, target, smooth=1.0):\n",
    "    p = pred.reshape(-1)\n",
    "    t = target.reshape(-1)\n",
    "    inter = (p * t).sum()\n",
    "    return 1 - (2*inter + smooth) / (p.sum() + t.sum() + smooth)\n",
    "\n",
    "def db_loss(prob_logits, prob, thresh, binary, gt_p, gt_b, gt_t, gt_tm):\n",
    "    # Prob loss: BCE(logits) + Dice\n",
    "    gt_p = gt_p.unsqueeze(1)\n",
    "    gt_b = gt_b.unsqueeze(1)\n",
    "    gt_t = gt_t.unsqueeze(1)\n",
    "    gt_tm = gt_tm.unsqueeze(1)\n",
    "\n",
    "    l_prob_bce = F.binary_cross_entropy_with_logits(prob_logits, gt_p)\n",
    "    l_prob_dice = dice_loss(prob, gt_p)\n",
    "    l_prob = l_prob_bce + l_prob_dice\n",
    "\n",
    "    # Binary loss: Dice (autocast-safe)\n",
    "    l_binary = dice_loss(binary, gt_b)\n",
    "\n",
    "    # Thresh loss: L1 within mask\n",
    "    if gt_tm.sum() > 0:\n",
    "        l_thresh = (torch.abs(thresh - gt_t) * gt_tm).sum() / (gt_tm.sum() + 1e-6)\n",
    "    else:\n",
    "        l_thresh = torch.tensor(0.0, device=prob.device)\n",
    "\n",
    "    return l_prob + l_binary + 10.0 * l_thresh\n",
    "\n",
    "def train():\n",
    "    torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "    train_ds = OCRDataset(TRAIN_IMG, TRAIN_JSON, train_tf)\n",
    "    val_ds = OCRDataset(VAL_IMG, VAL_JSON, val_tf)\n",
    "    train_dl = DataLoader(train_ds, BS, shuffle=True, num_workers=4,\n",
    "                          pin_memory=True, drop_last=True, persistent_workers=True)\n",
    "    val_dl = DataLoader(val_ds, BS, shuffle=False, num_workers=4,\n",
    "                        pin_memory=True, persistent_workers=True)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-2)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=LR, epochs=EPOCHS,\n",
    "        steps_per_epoch=len(train_dl)//ACCUM, pct_start=0.1)\n",
    "    scaler = GradScaler('cuda')\n",
    "    best = float('inf')\n",
    "\n",
    "    print(f\"=== DBNet Training ===\")\n",
    "    print(f\"    ResNet50 + FPN + DB Head, {SZ}x{SZ}\")\n",
    "    print(f\"    Batch {BS} x Accum {ACCUM} = {BS*ACCUM}\")\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        t_loss = 0\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        for i, (imgs, gp, gb, gt, gtm) in enumerate(tqdm(train_dl, desc=f\"E{ep}\")):\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            gp = gp.to(DEVICE, non_blocking=True)\n",
    "            gb = gb.to(DEVICE, non_blocking=True)\n",
    "            gt = gt.to(DEVICE, non_blocking=True)\n",
    "            gtm = gtm.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            with autocast('cuda', dtype=torch.bfloat16):\n",
    "                pl, p, th, bn = model(imgs)\n",
    "                loss = db_loss(pl, p, th, bn, gp, gb, gt, gtm) / ACCUM\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            if (i+1) % ACCUM == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer); scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                scheduler.step()\n",
    "            t_loss += loss.item() * ACCUM\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        v_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, gp, gb, gt, gtm in val_dl:\n",
    "                imgs = imgs.to(DEVICE)\n",
    "                gp, gb, gt, gtm = gp.to(DEVICE), gb.to(DEVICE), gt.to(DEVICE), gtm.to(DEVICE)\n",
    "                with autocast('cuda', dtype=torch.bfloat16):\n",
    "                    pl, p, th, bn = model(imgs)\n",
    "                    v_loss += db_loss(pl, p, th, bn, gp, gb, gt, gtm).item()\n",
    "\n",
    "        avg_t = t_loss / len(train_dl)\n",
    "        avg_v = v_loss / len(val_dl)\n",
    "        print(f\"E{ep}: train={avg_t:.4f} val={avg_v:.4f} lr={optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        if avg_v < best:\n",
    "            best = avg_v\n",
    "            torch.save(model.state_dict(), 'dbnet_best.pth')\n",
    "            print(f\"  -> Saved (best={best:.4f})\")\n",
    "\n",
    "        mem = torch.cuda.max_memory_allocated()/1e9\n",
    "        print(f\"  -> Peak VRAM: {mem:.1f}GB\")\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Done. Best val={best:.4f}\")\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Inference + Submission\n",
    "\n",
    "def inference():\n",
    "    print(\"=== DBNet Inference (Multi-Scale TTA) ===\")\n",
    "    model.load_state_dict(torch.load('dbnet_best.pth', map_location=DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    with open(TEST_JSON, 'r') as f:\n",
    "        test_data = json.load(f)['images']\n",
    "    names = list(test_data.keys())\n",
    "    normalize = A.Normalize()\n",
    "\n",
    "    scales = [896, 1024, 1152]\n",
    "    predictions = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for name in tqdm(names, desc=\"Inference\"):\n",
    "            img = cv2.imread(os.path.join(TEST_IMG, name))\n",
    "            if img is None:\n",
    "                predictions[name] = \"\"; continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            oh, ow = img.shape[:2]\n",
    "\n",
    "            acc = np.zeros((oh, ow), dtype=np.float32)\n",
    "            for sc in scales:\n",
    "                resized = cv2.resize(img, (sc, sc))\n",
    "                normed = normalize(image=resized)['image']\n",
    "                t = torch.from_numpy(normed.transpose(2,0,1)).float().unsqueeze(0).to(DEVICE)\n",
    "\n",
    "                with autocast('cuda', dtype=torch.bfloat16):\n",
    "                    _, p1, _, _ = model(t)\n",
    "                    _, p2, _, _ = model(torch.flip(t, [3]))\n",
    "                    p2 = torch.flip(p2, [3])\n",
    "\n",
    "                avg = ((p1 + p2) / 2).float().cpu().numpy()[0, 0]\n",
    "                acc += cv2.resize(avg, (ow, oh))\n",
    "\n",
    "            final = acc / len(scales)\n",
    "\n",
    "            # Post-processing\n",
    "            binary = (final > 0.6).astype(np.uint8)\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "            binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            polys = []\n",
    "            for cnt in contours:\n",
    "                if cv2.contourArea(cnt) < 80: continue\n",
    "                rect = cv2.minAreaRect(cnt)\n",
    "                if min(rect[1]) < 4: continue\n",
    "\n",
    "                eps = 0.01 * cv2.arcLength(cnt, True)\n",
    "                approx = cv2.approxPolyDP(cnt, eps, True)\n",
    "                if len(approx) >= 4:\n",
    "                    pts = approx.reshape(-1, 2)\n",
    "                else:\n",
    "                    pts = np.int32(cv2.boxPoints(rect))\n",
    "\n",
    "                # Expand polygon (recover from shrunk training)\n",
    "                expanded = expand_poly(pts, ratio=1.5)\n",
    "                if len(expanded) >= 4:\n",
    "                    polys.append(expanded.tolist())\n",
    "\n",
    "            if polys:\n",
    "                parts = [\" \".join(f\"{int(p[0])} {int(p[1])}\" for p in poly) for poly in polys]\n",
    "                predictions[name] = \"|\".join(parts)\n",
    "            else:\n",
    "                predictions[name] = \"\"\n",
    "\n",
    "    df = pd.read_csv(SAMPLE_SUB)\n",
    "    df['polygons'] = df['filename'].map(predictions).fillna(\"\")\n",
    "    df.to_csv('submission_dbnet.csv', index=False)\n",
    "\n",
    "    counts = df['polygons'].apply(lambda x: len(x.split('|')) if x else 0)\n",
    "    print(f\"Saved: submission_dbnet.csv\")\n",
    "    print(f\"Avg polygons/img: {counts.mean():.1f}, Min: {counts.min()}, Max: {counts.max()}\")\n",
    "\n",
    "inference()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
